Asymmetry in almost sure analysis of LTL:
As long as anything bad can happen, objective cannot be fulfilled.
But good things only require a non-zero probability and enough tries and they will eventually happen.
LTL only cares about ordering, except for $\Next$, no operator has a time limit on how long things may take.
One can reasonably conclude that avoiding bad stuff is more important than ensuring good stuff.


\startsubsection[title={Negative Attractor}]

    Introduced by \cite[Svorenova2017].
    Guaranteed bad-states.

    Extend by doing full Pre/Attr solution.
    Simplification possible by doing multiple iterations at once, but careful with loop (see section \in[sec:refinement-negative-loops]).

    Impossible to do better and still have a guarantee for reachability problem.
    Good idea to always do this wrt outer states as attractor of those will never be satisfying (unless part of final state of co-safe objective).

\stopsubsection


\startsubsection[title={Safety}]

    Negative attractor concerned with absolute unavoidability of bad things.
    State might be such that in the current system state bad things cannot be avoided, but after refinement the state can be made safe.
    Occurs when states are very big and require non-overlapping actions in different regions to stay safe.

    Called safe due to relation to safety property in state space (avoid the outer/no region).
    Can easily be detected using $Act$.
    Refinement is not obvious as in Negative Attractor as actions need to be considered.
    Positive refinement wrt undecided/yes states sufficient to ensure safety.
    Idea is to split into regions where required actions to stay safe are similar.

\stopsubsection


\startsubsection[title={Loops},reference={sec:refinement-negative-loops}]

    Remember that Player 2 selects where inside a state one starts, after Player 1 has selected control input.
    In reachability progress needs to be made towards the target.
    In big states, it might not be able to leave, adversarial player 2 can make a trace be stuck indefinitely for the purposes of the analysis.
    Example: go left works after a few steps, but abstraction does not allow precise position inside state, so Player 2 can reset trace again and again (in the abstracted world).
    Such self loops must be avoided.
    Additionally loops involving multiple states, avoiding the target, must be removed.

    Loop analysis is tricky, because it depends on the game.
    While this information is available directly after analysis, actions and supports need to be recomputed after any change which can be expensive.
    Furthermore, not all loops are problematic, since Player 1 might be able to avoid a loop by selecting an action that breaks the loop.
    Therefore game graph analysis is necessary to fully figure out loop situation.

    Cheap, conservative estimate for self-loops is possible using only polytopic operators.
    In some situations, this might be enough to remove all problematic loops, in others it leads to much unnecessary paritioning.
    See if $\Post$ intersects self and is not empty after Pontryagin difference with random space polytope.
    Then robust predecessor exists in self, and self-loop can potentially exist.
    No statement possible if loop is actually problematic as specific actions are not considered.
    With positive refinement, states can be partitioned to remove such loops if desired.

\stopsubsection

