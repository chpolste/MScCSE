A decomposition approach is presented that extracts a series of reachability problems from the product game.
These sub-problems are solved with positive robust refinement, which is computationally inexpensive even when multi-step dynamics is taken into account.
Solutions of the sub-problems are transferred back to the product game through refinement.
When all reachability problems have been solved, a solution for the original problem emerges.


\startsubsection[title={Transition-based Reachability Decomposition},reference=sec:refinement-transition-decomposition]

    Decompose product game into series of co-safe reachability problems based on the transitions of the objective automaton.
    Idea is again based on the stuttering equivalence of traces with respect to a $\Next$-free LTL formula.
    Solve reachability for every individual automaton transition an assemble solution strategy from the partial strategies that enable a change of the automaton state.

    Example: recurrence objective from Table \in[tab:theory-logic-objectives].
    Goal is to realize the accepting run $(q_0 q_1)^\omega$ in the product game (there are other accepting runs, but this one is chosen here).
    Recurrence is $\Next$-free, therefore any run of the form $q_0^+ q_1^+ q_0^+ q_1^+ ...$ is also accepting.
    Decompose system into two co-safe reachability problems:
    $\mathcal{R}_{q_0 \rightarrow q_1}$, whose objective is to reach a $q_1$ state from the $q_0$ states of the product game, and $\mathcal{R}_{q_1 \rightarrow q_0}$, whose objective is to reach a $q_0$ state from the $q_1$ states of the product game.
    Assume that solutions to these problems have been found and the sets of satisfying initial states of the state space $\InitialStates^{\mathcal{R}_{q_0 \rightarrow q_1}}$ and $\InitialStates^{\mathcal{R}_{q_1 \rightarrow q_0}}$ are known.
    Then for every $\VecState \in \InitialStates^{\mathcal{R}_{q_0 \rightarrow q_1}}$, there exists a player 1 strategy $\Strategy{1}{q_0 \rightarrow q_1}$ that leads a trace to a state space region where the associated play switches to a $q_1$ state almost-surely and in finite time.
    A strategy $\Strategy{1}{q_1 \rightarrow q_0}$ exists analogously for all $\VecState \in \InitialStates^{\mathcal{R}_{q_1 \rightarrow q_0}}$.

    Based on these strategies an almost-sure winning strategy for the recurrence objective of the complete product game can be assembled.
    Let $x$ be a trace starting in some state $\Tuple{\State{i}}{q_0}$.
    Player 1 plays with $\Strategy{1}{q_0 \rightarrow q_1}$ until a state $\Tuple{X_j}{q_1}$ is reached.
    Then player 1 switches to strategy $\Strategy{1}{q_1 \rightarrow q_0}$ until a state $\Tuple{X_k}{q_0}$ is reached.
    Then player 1 switches back to strategy $\Strategy{1}{q_0 \rightarrow q_1}$.
    Alternating between both strategies in this fashion guarantees satisfaction of the recurrence objective as long as the trace does not leave the solution regions $\InitialStates^{\mathcal{R}_{q_0 \rightarrow q_1}}$ and $\InitialStates^{\mathcal{R}_{q_1 \rightarrow q_0}}$.
    Note that each strategy is guaranteed to achieve its reachability goal in finite time as the sub-problems are interpreted in the co-safe setting.

    The example illustrates the principle of how a solution for the original problem can emerge from solutions to the problems generated by the transition-based reachability decomposition.
    Formalize the construction of a reachability sub-problem $\mathcal{R}$ based on an automaton transition from $q$ to $q'$.
    The system is based on the same LSS $\LSS$ as the product game and initially uses its state space partition.
    The partition elements are sorted into 3 categories.
    First,

    \startformula
        \ReachStates{q}{q'} = \Set{ \State{i} \mid \Tuple{\State{i}}{q} \in P_1 \MidAnd \State{i} \notin \NoStates{q} \MidAnd ( \QNext{i}{q} = q' \MidOr \YesStates{q} ) } \EndComma
    \stopformula

    the elements whose union has to be reached.
    These are parts where a transition to the target automaton state happens with any of the next player 1 actions in the product game.
    It also includes all parts that have already been recognized as satisfying for the origin $q$ by a previous analysis.
    Second,

    \startformula
        \RefineStates{q}{q'} = \Set{ \State{i} \mid \Tuple{\State{i}}{q} \in P_1 \MidAnd \State{i} \notin \NoStates{q} \MidAnd \QNext{i}{q} = q } \EndComma
    \stopformula

    the elements which do not trigger an automaton transition with their player 1 actions.
    These elements will be refined.
    Due to stuttering equivalence any number of steps inside this region can be made as long as the number is finite.
    And finally,

    \startformula
        \AvoidStates{q}{q'} = \IndexedStates{i}{I} \setminus \left( \ReachStates{q}{q'} \cup \RefineStates{q}{q'} \right) \EndComma
    \stopformula

    the elements where a transition to any other automaton state happens with the next player 1 action, as well as all elements from the no-set of the previous analysis.
    These states are to be avoided.
    The three sets are disjunct except for the special case $q = q'$, where $\ReachStates{q}{q'} \cap \RefineStates{q}{q'} \ne \emptyset$.
    To summarize, the goal is to refine the state space partition elements in $\RefineStates{q}{q'}$, such that $\ReachStates{q}{q'}$ can be reached almost-surely in finite time while avoiding $\AvoidStates{q}{q'}$.

\stopsubsection


\placefigure[top][fig:refinement-transition-jagged]{
    Illustration of how jaggedness in a positive refinement target region causes very fine partitioning and how post-processing of $\RefinePos$ can reduce the number of generated state space partition elements.
    See section \in[sec:refinement-transition-reachability] for a detailed discussion.
}{
    \bTABLE
        \setupTABLE[frame=off]
        \bTR
            \bTD[nc=2] (a) no post-processing \eTD
        \eTR
        \bTR
            \bTD \externalfigure[refinement-transition-jagged-ref-attrr][width=0.47\textwidth] \eTD
            \bTD \externalfigure[refinement-transition-jagged-ref-ana][width=0.47\textwidth] \eTD
        \eTR
        \bTR
            \bTD[nc=2] (b) convex hull \eTD
        \eTR
        \bTR
            \bTD \externalfigure[refinement-transition-jagged-hull-attrr][width=0.47\textwidth] \eTD
            \bTD \externalfigure[refinement-transition-jagged-hull-ana][width=0.47\textwidth] \eTD
        \eTR
        \bTR
            \bTD[nc=2] (c) small state suppression, one iteration \eTD
        \eTR
        \bTR
            \bTD \externalfigure[refinement-transition-jagged-sup1-attrr][width=0.47\textwidth] \eTD
            \bTD \externalfigure[refinement-transition-jagged-sup1-ana][width=0.47\textwidth] \eTD
        \eTR
        \bTR
            \bTD[nc=2] (d) small state suppression, two iterations \eTD
        \eTR
        \bTR
            \bTD \externalfigure[refinement-transition-jagged-sup2-attrr][width=0.47\textwidth] \eTD
            \bTD \externalfigure[refinement-transition-jagged-sup2-ana][width=0.47\textwidth] \eTD
        \eTR
    \eTABLE
}

\startsubsection[title={Robust Reachability Refinement},reference=sec:refinement-transition-reachability]

    In section \in[sec:refinement-holistic-positive] a positive refinement procedure was presented based on the $\RefinePos$ kernel.
    Limitation was that yes-states have to exist for method to be applicable.
    While this is not generally a given, any co-safe objective has yes-states guaranteed.
    In particular, this includes the reachability/avoidance systems from the transition decomposition.

    Idea is to construct a multi-step refinement procedure based on robust dynamics.
    Positive robust refinement has progress guarantee.
    One-step robust reachability can generally be decided with the $\ActR$ operator without need for game construction (see section \in[sec:refinement-robust]).
    Restriction to robust reachability allows skipping of expensive game construction for analysis.
    While this means that the probabilistic dynamics is ignored completely, abstraction step is removed and entire procedure has polynomial complexity.
    Best of both worlds: multi-step refinement in the robust framework, but consideration of probabilistic dynamics by analysing every couple of refinements.

    Procedure: evolution of \cite[Svorenova2017] positive refinement to multi-step procedure based on reachability decomposition.
    First pick a transition and extract reachability problem.
    Refine every state wrt target region using $\RefinePos$ refinement.
    Use $ActR$ condition to determine states for which robust reachability is fulfilled.
    Extend target region with new yes states.
    Refine again wrt to the extended target region and iterate for a given number of times.
    Transfer partition to full system and analyse.

    Additional tweaks possible to improve method.
    Known that small states cannot be targeted individually due to probabilistic dynamics have no self loops and are therefore unlikely to be a problem if surrounded by bigger states for which robust satisfaction can be established.
    Expansion of target region can be accelerated by considering all small polytopes as satisfying (without proper probabilistic check).
    This brings some of the probabilistic tolerance back into the robust dynamics at the cost of losing the progress guarantee for a few special cases (practice shows that ignoring small states is not an issue as long as they are safe).

    Post-processing of $\RefinePos$ can improve refinement performance significantly.
    Idea is to over- or underapproximate the robust region from $\RefinePos$ in order to decrease size of state space partition.
    Overapproximation has the potential to accelerate progress but no guarantees exist.
    Underapproximation inherits guarantee at the cost of progress per step.
    Figure \in[fig:refinement-transition-jagged] illustrates the problem of over-refinement and how post-processing affects the complexity of the state space partition.
    Situation after one step of robust refinement for the double integrator test system introduced later in section \in[sec:cases-integrator].
    Green states are recognized yes-states and the reachability target.
    Implementation of $\RefinePos$ using $\AttrR$, according to Algorithms \in[alg:refinement-robust-kernel] and \in[alg:refinement-robust-control].
    Orange states are $\AttrR$-region determined in refinement.
    Issue here is jaggedness of target region, which is reflected and amplified in the $\AttrR$-region.

    Easy to see that refinement without post-processing (a) can quickly lead to a snowball effect as jaggedness increases with every iteration and moves to smaller scales.
    Overapproximation shown in (b), method is to take $\AttrR$-region of every state that is refined and refine with respect to its convex hull.
    Cut away region is always a polytope, increase in complexity of state space partition mainly by convex partitioning of remaining region.
    Issue: progress guarantee lost in general (in the figure, the analysis on the right shows that in this case it works out).
    Underapproximation in (c) by dropping polytopes $Y$ where $Y \ominus W = \emptyset$ from the $\AttrR$-region.
    This reduces small-scale jaggedness while keeping the progress guarantee intact.
    Possiblility to compensate for less progress by going to multi-step robust refinement.
    2-iteration robust refinement shown in (d), first iteration is orange, second yellow.
    Similar state count as no post-processing after one iteration but much volume recognized as yes-states in the analysis.
    More progress than convex hull approximation with only a few states more but full progress guarantee.

\stopsubsection


\startsubsection[title={Layered Robust Reachability Refinement},reference=sec:refinement-transition-layered]

    \cite[Svorenova2017] introduced the idea of a layer decomposition that works only for reachability but splits problem into multiple decoupled subproblems.
    Use one-step reachability property of predecessor to generate layers and then solve single-step reachability for each layer wrt its inner companion.
    Problem: $\AttrR$-based refinement is robust but they used the non-robust $\Pre$.
    However, for robust refinement, importance of the PreR also recognized by \cite[Svorenova2017].
    Propsal: combine transition decomposition, layer decomposition and robust refinement.
    Use PreR which is more aligned with robust refinement and provides guarantee that single-step robust solution can be found.
    Hybrid approach between multi-step and single-step: general idea of using the layers to move towards the target is multi-step, but transitions from layer to layer individually are single step.

    Advantages: decoupling into more, simpler subproblems.
    Limits jaggedness since $\PreR$ of a convex target region is convex (for convex control region).
    Prescribes basic structure of progress towards target, limits the effects of the randomization introduced in $\GetCtrl$
    Parallelization possible.
    But solution for outer layers depends on solution of inner layers otherwise multi-step concept falls apart.

    Procedure:
    First extract reachability problem for transition.
    Then decompose reachability problems into PreR layers. % TODO formulas!
    Solve reachability problem for each layer-to-layer transition.
    Combine into solution for reachability problem.
    Apply partition to product game.

    To combat problem of \epsilon-limit behaviour, shrink layer-generating control space.
    Other optimizations from robust refinement still apply (target expansion, ignoring of small but safe states, post-processing).

\stopsubsection


\startsubsection[title={Transition Selection},reference=refinement-transition-selection]

    If refinement wrt every transition has taken place, full problem should be decidable.
    The state space partition of the product system is shared between all copies for the automaton states.
    The individual reachability problems for each transition are therefore weakly linked, i.e.\ they can all be solved independently in parallel and then combined into one partition or they can be solved sequentially such that the partitions from earlier refinements potentially provide partial solutions to later reachability problems.
    Finding a \quotation{best} order of these refinements is again a non-trivial task.
    For co-safe objectives, it makes sense to work backwards from the final states, which are guaranteed to be satisfying.
    For infinite objectives a best path through the automaton is not obvious and multiple paths may even be required to find all satisfying initial states.
    Related to controller synthesis problem.

\stopsubsection

