The idea of an abstraction is to reduce a system to a set of equivalence classes, also called abstract states, whose possibly infinitely many member states of the original system share certain properties and behavior.
Capturing exactly those features from the original system which are required to carry out an analysis with respect to some specification is a challenging task.
Instead of going directly from the system to an abstraction on which the model checking problem can be fully decided, a hierarchy of intermediate system models can be constructed (iteratively) during the analysis procedure.
Starting from a very coarse abstraction of the system, models become more refined when moving down the hierarchy towards the original system with all its complexity.
If some abstraction in the hierarchy can be verified to meet the specification, all its refinements, including the original system, fulfill the specification as well.
This is because an abstraction can do at least everything its refinements can do.
In other words, for every behaviour in the refinement an equivalent exists in the abstraction, so if all behaviour of the abstraction meets the specification, all behaviour of its refinements will too. % TODO refinement ... refinements ... refinement
It is important to note that this is an asymmetric, one-way relation: if a refined model meets a specification, its higher level abstrations generally do not fulfill the specification as well.

Iterative abstraction refinement constructs the abstraction hierarchy top-down until a system model is found for which the model checking problem can be decided.
First, the the verification procedure is applied on an initial, coarse abstraction of the system of interest.
Because the abstraction is coarse, it is likely that it does not meet the specification and a counterexample is found.
This counterexample has to be recreated in the original system in order to distinguish actual counterexamples, which can be realized in the original system, from spurious ones, which emerge from behaviour that is exclusive to the abstraction.
If an actual counterexample is encountered, the original system does not meet the specification and the verification procedure terminates.
If a spurious counterexample is encountered, the abstraction is refined such that the behaviour from the counterexample is removed.
The procedure then starts a new verification-refinement-cycle with the newly obtained abstraction and iterates no counterexample is found any longer or a non-spurious counterexample is encountered.

Because the counterexamples found in higher levels of the abstraction hierarchy inform the refinement that produces lower-level abstractions, this procedure is called counterexample-guided abstraction refinement (CEGAR). % TODO reference
CEGAR is an effective way to automatically generate system models that adapt to the specific requirements of a given problem.
Ideally, its abstractions expose only the minimal complexity and behaviour required to carry out the desired analysis.
In practice, the refinement steps are not always obvious even when a counterexample is available and therefore driven by imperfect heuristics, which have to be carefully tuned for the problems at hand.
Nevertheless, the flexibility of CEGAR makes it an important tool, applied frequently in model checking procedures.

% TODO the CEGAR part seems too specific at this stage of the narrative. Postpone the mention until the actual refinement procedures are implemented.

