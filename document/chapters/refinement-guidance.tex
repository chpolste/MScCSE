When given a partition of the state space, that is too coarse and therefore does not permit a membership decision with respect to $\InitialStates$ for every state, how can one determine which parts to refine and how should that refinement look like?
Because the analysis is guaranteed to return a partial result (soundness), the states that require refinement can be limited to the set $\Set{ \State{i} \mid \exists q \in Q : \State{i} \in \MaybeStates{q} }$.
However, the analysis procedure does not return specific counterexamples of plays where player 2 wins with non-zero probability but sets $P_{\Yes}$, $P_{\No}$ and $P_{\Maybe}$.
In order to refine undecided states, knowledge of the game graph and the LSS dynamics have to be used in addition to the analysis results.

\cite[Svorenova2017] separated their refinement procedures into two categories named positive and negative.
Positive refinement has the goal of enlarging the total volume of polytopes in $P_\Yes$ while negative refinement aims to enlarge the volume of polytopes in $P_\No$.
For simple objectives such as reachability, the analysis will provide feedback to a refinement more immediately than for complex objectives, where multiple refinement steps might have to be taken until the first states of $\ProductGame$ can be decided by the analysis.
Refinement should therefore not exclusively rely on the sets $P_{\Yes}$, $P_{\No}$ and $P_{\Maybe}$ or else the abstraction-analysis-refinement procedure could get stuck if progress halts at any point in time.
For non-co-safe objectives, it is also not guaranteed that $P_{\Yes}$ contains any state at all. % TODO

Here, an additional class called neutral refinement is introduced, motivated by the following observations:
A single \quotation{bad} transition that cannot be avoided with probability 1 enables player 2 to win the game.
At the same time, a \quotation{good} transition need only occur somewhere with non-zero probability in a \quotation{neutral} environment and player 1 can still almost-surely satisfy an objective. 
LTL only determines the order of events and, aside from the $\Next$-operator, not the temporal distance between them.
So in almost-sure verification of an LTL objective without $\Next$ there is no need to satisfy the objective in an efficient manner.
Player 1 can take any finite amount of time to arrive at a good transition as long the environment is neutral, i.e.\ as long as states in which player 2 can force a bad transition can be avoided almost-surely. % TODO mention stuttering equivalence?
Hence, avoiding bad transitions is arguably just as important as enabling good transitions.
Procedures in the category of neutral refinement make it possible to avoid bad transitions for longer by breaking patterns in the game graph that allow player 2 to win, therefore creating a neutral environment for player 1.
An almost-sure winning player 1 strategy for the objective may not immediately exist after a neutral refinement step but finding one through positive refinement should have become easier.

The design of fully automated refinement is highly non-trivial.
With multiple refinement procedures at one's disposal, questions arise about the order in which procedures should be applied, how often they should be applied and how often the system should be analysed between refinement steps.
General answers to these questions are hard to find, as the best strategy for refinement coordination will depend on the objective, the properties of the LSS and even on the meaning of \quotation{best}.
One can optimize for the shortest time until a certain percentage of the state space is decided in the analysis, the smallest number of states generated in the partition, the suitability of the generated game graph for controller synthesis purposes and many other metrics.
If optimizing for performance, note has to be taken that application of a refinement procedure invalidates (parts of) the game graph.
When chaining refinement procedures without an intermediate analysis, procedures relying on insights from the game graph incur significant additional computational cost as the game's actions have to be recomputed, which involves operations of exponential complexity in the number of states.
Procedures based only on the system dynamics have the advantage of being chainable without extra computational cost.

