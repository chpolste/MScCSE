The idea of an abstraction is to reduce a system to a set of equivalence classes, also called abstract states, whose possibly infinitely many member states of the original system share certain properties and/or behavior.
Capturing exactly those features from the original system which are required to carry out an analysis with respect to some specification is a challenging task.
Instead of going directly from the system to an abstraction on which the model checking problem can be decided, a hierarchy of intermediate system models can be constructed.
Starting from a very coarse abstraction of the system, models become more refined when moving down the hierarchy towards the original system with all its complexity.
If some abstraction in the hierarchy has been verified to meet the specification, all its refinements, including the original system, fulfil the specification as well.
This is because an abstraction can do everything its refinements can do and generally more.
In other words, for every behaviour in the refinement an equivalent exists in the abstraction, so if all behaviour of the abstraction meets the specification, all behaviour of its refinements will too.
It is important to note that this is an asymmetric, one-way relation: if a refined model meets a specification, its higher level abstrations generally do not fulfill the specification too.

In iterative abstraction refinement, the abstraction hierarchy is constructed top-down until a model is found for which the model checking problem can be decided.
One starts by applying the verification procedure on an initial, coarse abstraction of the system of interest.
Because the abstraction is coarse, it is likely that it does not meet the specification and a counterexample is found.
This counterexample has to be recreated in the original system in order to distinguish actual counterexamples, which can be realized in the original system, from spurious ones, which emerge from behaviour that is exclusive to the abstraction.
If an actual counterexample is encountered, the original system does not meet the specification and the verification procedure terminates.
If a spurious counterexample is encountered, the abstraction is refined such that the behaviour from the counterexample is removed during refinement.
The procedure then starts a new verification-refinement-cycle with the newly obtained abstraction and iterates until the abstration is sufficently close to the original system and the verification problem can be decided.

Because the counterexamples encountered in higher levels of the abstraction hierarchy inform the refinement that produces lower-level abstractions, this procedure is called counterexample-guided abstraction refinement (CEGAR).
CEGAR is an effective way to generate system models that adapt to the requirements of a specific problem.
Ideally, its abstractions expose only the minimal complexity and behaviour required to carry out the desired analysis.
In practice, the refinement steps are not always obvious and driven by imperfect heuristics, which have to be carefully tuned for the problems at hand.
Nevertheless, the flexibility of CEGAR makes it an important tool, applied frequently in model checking procedures.

