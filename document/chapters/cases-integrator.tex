This case study replicates the problem setup of \cite[Svorenova2017].
The system under consideration evolves according to the discrete-time double integrator dynamics

\startformula
    \VecX_{t+1} = \TwoByTwo{1}{1}{0}{1} \VecState_{t} + \TwoByOne{0.5}{1} \VecControl_{t} + \VecRandom_{t} \EndComma
\stopformula

where $\VecState_{t} \in \StateSpace = \ClosedInterval{-5}{5} \times \ClosedInterval{-3}{3}$, $\VecControl_{t} \in \ControlSpace = \ClosedInterval{-1}{1}$ and $\VecRandom_{t} \in \RandomSpace = \ClosedInterval{-0.1}{0.1}^2$.
The problem is therefore mixed-dimensional, with a two-dimensional state space and 1-dimensional control space.
The objective is to eventually reach the polytope $\ClosedInterval{-1}{1}^2$ almost-surely, i.e.\ a reachability problem with formula

\startformula
    \Finally ( \Predicate_{1} \wedge \Predicate_{2} \wedge \Predicate_{3} \wedge \Predicate_{4} ) \EndComma
\stopformula

where the linear predicates $\Predicate_{1}$, $\Predicate_{2}$, $\Predicate_{3}$ and $\Predicate_{4}$ correspond to halfspaces governed by the inequalities $x \leq 1$, $-x \leq 1$, $y \leq 1$ and $-y \leq 1$.
The co-safe interpretation of The objective is chosen and the automaton from \in{Table}[tab:TODO] used.
The initial state space decomposition and the extended state space are visualized in \in{Figure}[fig:cases-integrator-initial].

\cite[Svorenova2017] have demonstrated that positive robust refinement is viable for this problem, so it is used here as a testbed for different configurations of robust refinement techniques.
Double integrator dynamics were also used as an example by \cite[AydinGol2015] but in a non-probabilistic setting.

\placefigure[top][fig:cases-integrator-initial]{
    The double integrator test system and its initial partition.
    Polytopes $\State{1}$ to $\State{4}$ (grey) are outer states from the decomposition of $\ExtendedStateSpace \setminus \StateSpace$.
    The reachability target is $\State{12}$ (green).
}{
    \externalfigure[cases-integrator-initial][width=\textwidth]
}


\startsubsection[title={Negative Refinement},reference=sec:cases-integrator-negative]

    \placetable[top][tab:cases-integrator-negative]{
        Initial analysis and negative attractor refinement for the double integrator system.
        The refinement procedure converged after 3 iterations.
        Polytopes in $\YesStates{q_0}$ are coloured green, polytopes in $\NoStates{q_0}$ grey and white polytopes are from $\MaybeStates{q_0}$.
        See \in{section}[sec:cases-integrator-negative] for discussion.
    }{
        \RefinementTable{
            \RefinementTableRow[iteration=1,polys=9,onestates=28,oneactions=44,twostates=26,twoactions=216,
                                total={0:00},refinement={-},gamegraph={0:00},analysis={0:00},
                                yes=6.7,no=0.0,maybe=93.3,figure=cases-integrator-iteration1]
            \RefinementTableRow[iteration=2,polys=13,onestates=36,oneactions=60,twostates=38,twoactions=362,
                                total={0:00},refinement={0:00},gamegraph={0:00},analysis={0:00},
                                yes=6.7,no=11.3,maybe=82.1,figure=cases-integrator-iteration2]
            \RefinementTableRow[iteration=3,polys=17,onestates=44,oneactions=80,twostates=50,twoactions=592,
                                total={0:01},refinement={0:00},gamegraph={0:00},analysis={0:00},
                                yes=6.7,no=16.1,maybe=77.3,figure=cases-integrator-iteration3]
            \RefinementTableRow[iteration=4,polys=21,onestates=52,oneactions=104,twostates=66,twoactions=794,
                                total={0:01},refinement={0:00},gamegraph={0:00},analysis={0:00},
                                yes=6.7,no=17.1,maybe=76.2,figure=cases-integrator-iteration4]
        }
    }

    Before applying a positive refinement procedure, negative attractor (\in{section}[sec:refinement-holistic-negattr]) refinement is applied.
    The initial negative region is made up from the outer polytopes of the system.
    3 iterations of the refinement-abstraction-analysis cycle are shown in \in{Table}[tab:cases-integrator-negative] (2-4).
    As guaranteed by the refinement method, the attractor regions are immediately recognized as members of $\NoStates{q_0}$.
    After 3 iterations, the attractor has converged and no additional progress is made.

    In addition to a depiction of the state space partition after each refinement step in \in{Table}[tab:cases-integrator-negative], the elapsed time since problem initialization and the number of polytopes in the current state space partition are stated above the figures.
    Also reported are the size of the 2Â½-player game abstraction as player 1 and 2 state and action counts, the elapsed time during refinement application, game graph construction and analysis as well as the volume fraction of the regions $\YesStates{q_0}$ (yes), $\NoStates{q_0}$ (no) and $\MaybeStates{q_0}$ (maybe) with respect to the state space polytope $\StateSpace$.
    The table shows that refinement, abstraction and analysis in all iterations took less than 1 second.
    The initial analysis and the negative refinement required 1 second of run time in total.

    % TODO? Show that simplification with multiple iterations of negative attractor does not generally work because of self-loops.

\stopsubsection



\startsubsection[title={Positive Robust Refinement},reference=sec:cases-integrator-positive]

    \placetable[top][tab:cases-integrator-positive-single]{
        Refinement of transition $q_0 \rightarrow q_1$ of the double integrator system using 4 iterations of positive robust single-step refinement, applied twice in each iteration without robust target expansion.
        See \in{section}[sec:cases-integrator-positive] for discussion.
    }{
        \RefinementTable{
            \RefinementTableRow[iteration=5,polys=48,onestates=106,oneactions=476,twostates=407,twoactions=6188,
                                total={0:04},refinement={0:00},gamegraph={0:03},analysis={0:00},
                                yes=13.9,no=17.1,maybe=68.9,figure=cases-integrator-iteration5-prs]
            \RefinementTableRow[iteration=6,polys=166,onestates=342,oneactions=3723,twostates=3519,twoactions=79332,
                                total={2:07},refinement={0:02},gamegraph={1:59},analysis={0:03},
                                yes=36.5,no=17.1,maybe=46.4,figure=cases-integrator-iteration6-prs]
            \RefinementTableRow[iteration=7,polys=301,onestates=612,oneactions=5902,twostates=5459,twoactions=111705,
                                total={5:59},refinement={0:09},gamegraph={3:40},analysis={0:03},
                                yes=54.9,no=17.1,maybe=28.0,figure=cases-integrator-iteration7-prs]
            \RefinementTableRow[iteration=8,polys=362,onestates=734,oneactions=3096,twostates=2458,twoactions=54578,
                                total={9:41},refinement={0:07},gamegraph={3:33},analysis={0:02},
                                yes=67.0,no=17.1,maybe=15.9,figure=cases-integrator-iteration8-prs]}
    }

    \placetable[top][tab:cases-integrator-positive-double]{
        Refinement of transition $q_0 \rightarrow q_1$ of the double integrator system using 4 iterations of positive robust two-step refinement with robust target expansion.
        See \in{section}[sec:cases-integrator-positive] for discussion.
    }{
        \RefinementTable{
            \RefinementTableRow[iteration=5,polys=68,onestates=146,oneactions=885,twostates=796,twoactions=13251,
                                total={0:11},refinement={0:00},gamegraph={0:10},analysis={0:00},
                                yes=18.4,no=17.1,maybe=64.5,figure=cases-integrator-iteration5-prm]
            \RefinementTableRow[iteration=6,polys=236,onestates=482,oneactions=6293,twostates=6003,twoactions=141782,
                                total={4:32},refinement={0:06},gamegraph={4:08},analysis={0:06},
                                yes=53.9,no=17.1,maybe=29.0,figure=cases-integrator-iteration6-prm]
            \RefinementTableRow[iteration=7,polys=333,onestates=676,oneactions=4114,twostates=3567,twoactions=53441,
                                total={6:09},refinement={0:06},gamegraph={1:29},analysis={0:02},
                                yes=77.0,no=17.1,maybe=5.9,figure=cases-integrator-iteration7-prm]
            \RefinementTableRow[iteration=8,polys=361,onestates=732,oneactions=1367,twostates=682,twoactions=7436,
                                total={6:18},refinement={0:01},gamegraph={0:08},analysis={0:00},
                                yes=82.5,no=17.1,maybe=0.3,figure=cases-integrator-iteration8-prm]
        }
    }

    The first positive refinement procedure tested on the double integrator is constructed to resemble that of \cite[Svorenova2017] (see their chapter 5 and Figure 6).
    Their robust refinement kernel was driven by control regions selected based on the player 1 actions of the game and they applied the kernel three times between each analysis.
    The robust predecessor of the recognized yes-region was used to refine the system.
    Here, only the kernel refinement is applied but with 2 applications between each analysis as the sampling-based control region selection is generally more effective than action-based selection and progress per iteration is therefore similar.

    The progress from 4 iterations of refinement together with the familiar performance metrics are shown in \in{Table}[tab:cases-integrator-positive-single].
    They are labeled iterations 5 to 8 to indicate that the procedure from the negative refinement is continued.
    The size of the state space partition doubles after the first iteration of refinement and then more than triples in the next iteration.
    A large amount of small states are created to the upper left and lower right of the target region.
    The asymmetry of the partitioning outside of the robust attractor region is due to the implementation of the geometric operations.
    Here, the partitioning in the lower right corner is favourable and leads to additional progress that is not seen in the upper left.
    This allows faster progress in the upper right half of the state space in the 2 subsequent iterations whereas many small states are created in the upper left.
    The polygon count exceeds 300 after 3 iterations and increases only by 61 in the 4th.
    After the final iteration, 84\% of the state space volume has been categorized as parts of $\InitialStates$ or $\StateSpace \setminus \InitialStates$.
    The elapsed time is just under 10 minutes with most of the time spent in the construction of the game abstraction.

    Compared to the results of \cite[Svorenova2017] it can be noted that the amount of progress after 4 iterations is similar, but the partition generated here has more states.
    This can partially be attributed to the omission of the $\PreR$ refinement which seems to reduce overall jaggedness aroung the $\AttrR$-regions.

    The decomposition into robust reachability problems for specific automaton transitions enables multi-step refinement with an expanding target region.
    The double integrator problem is already a reachability problem and co-safe, therefore the decomposition is trivial here and the transition $q_0$ to $q_1$ is chosen.
    A single-step method was applied twice between analyses in the previous experiment, now a two-step method is applied once.
    4 iterations of this refinement procedure are shown in \in{Table}[tab:cases-integrator-positive-double].
    Immediately in the first iteration, progress is faster than with the single-step scheme with 20 additional polytopes generated.
    The second iteration more than triples the partition size which leads to a costly game graph abstraction taking 4 minutes.
    Progress after this iteration however is comparable to that of the third iteration of the single-step method.
    The next 2 iterations grow the partition size by 125, with relatively short game graph construction times due to game simplification based on the fast progress in the first 2 iterations.
    Only 0.3\% of the state space volume remain undecided after 4 iterations with an elapsed time that is more than 3 minutes shorter than that of the single-step method.

    \placetable[top][tab:cases-integrator-positive-suppressed]{
        Refinement of transition $q_0 \rightarrow q_1$ of the double integrator system using 4 iterations of positive robust two-step refinement with robust target expansion and small state suppression.
        See \in{section}[sec:cases-integrator-positive] for discussion.
    }{
        \RefinementTable{
            \RefinementTableRow[iteration=5,polys=51,onestates=112,oneactions=507,twostates=435,twoactions=6147,
                                total={0:05},refinement={0:00},gamegraph={0:04},analysis={0:00},
                                yes=18.5,no=17.1,maybe=64.3,figure=cases-integrator-iteration5-prms]
            \RefinementTableRow[iteration=6,polys=99,onestates=208,oneactions=1360,twostates=1221,twoactions=21859,
                                total={0:26},refinement={0:02},gamegraph={0:18},analysis={0:01},
                                yes=42.4,no=17.1,maybe=40.4,figure=cases-integrator-iteration6-prms]
            \RefinementTableRow[iteration=7,polys=134,onestates=278,oneactions=1291,twostates=1069,twoactions=16174,
                                total={0:41},refinement={0:02},gamegraph={0:13},analysis={0:00},
                                yes=65.6,no=17.1,maybe=17.3,figure=cases-integrator-iteration7-prms]
            \RefinementTableRow[iteration=8,polys=161,onestates=332,oneactions=962,twostates=671,twoactions=8157,
                                total={0:48},refinement={0:01},gamegraph={0:05},analysis={0:00},
                                yes=80.1,no=17.1,maybe=2.7,figure=cases-integrator-iteration8-prms]
        }
    }

    The two-step refinement is applied again with two modifications:
    First, any state $Y$ with $Y \ominus \RandomSpace$ is not further refined unless the probability of reaching the no-region is non-zero for all control inputs.
    Second, the $\RefinePos$ partition is post-processed such that polytopes $Y$ where $Y \ominus \RandomSpace$ are removed from the $\AttrR$-region, as shown in \in{Figure}[fig:refinement-transition-jagged](d).
    4 iterations of this modified refinement are presented in \in{Table}[tab:cases-integrator-positive-suppressed].
    As expected, progress per iteration is slower than without post-processing but the state space explosion is significantly reduced because the refinement is able to handle jaggedness without it being propagated to smaller scales.
    After 4 iterations that took only a tenth of the time of the unmodified procedure less than half the number of partition elements were generated and only 2.7\% of the system was left undecided.

    Similar partitioning is also achieved if a single iteration with an eight-step procedure is carried out (not shown), although the overall elapsed time is longer because the game construction cannot benefit from intermediate results.
    Applying an overapproximating post-processing using the convex hull as shown in \in{Figure}[fig:refinement-transition-jagged](b) resulted in varying performance (not shown).
    While the overapproximation would sometimes work out and the system would continuously progress, the procedure could also get stuck due to the missing progress guarantee.

\stopsubsection


\startsubsection[title={Positive Robust Refinement with Layer Decomposition},reference=sec:cases-integrator-layered]

    \placetable[top][tab:cases-integrator-layered-original]{
        Refinement of transition $q_0 \rightarrow q_1$ of the double integrator reachability system using a layer decomposition generated by the robust predecessor and four-step positive robust refinement with robust target expansion small state suppression.
        See \in{section}[sec:cases-integrator-layered] for discussion.
    }{
        \RefinementTable{
            \RefinementTableRow[iteration=5,polys=166,onestates=342,oneactions=4364,twostates=4177,twoactions=79056,
                                total={1:24},refinement={0:03},gamegraph={1:16},analysis={0:05},
                                yes=76.3,no=17.1,maybe=6.6,figure=cases-integrator-iteration5-lprms]
        }
    }

    The layer decomposition approach offers an alternative approach to multi-step refinement.
    It is now applied together with the underapproximated robust refinement from the previous section.
    The robust predecessor is chosen as the layer generating operator.
    Because reachability from the outer layers depends on the solution of the inner layers, up to 4 robust refinement steps are applied to each layer in order to increase the likelihood of successful refinement.

    \in{Table}[tab:cases-integrator-layered-original] shows the partitioning and performance metrics for a layered decomposition refinement.
    The $\PreR$ recurrence converged after 7 layers were generated.
    The size of the resulting state space partition is similar to that of the final iteration of the post-processed two-step refinement but the elapsed time to solution is longer, since no intermediate analysis results are available for game simplification.
    It also fails to guarantee almost-sure reachability for some polytopes from the 2 outermost layers.
    This is likely related to the small-state suppression as these polytopes are relatively long and thin and any further refinement is rejected by the post-processing.
    Long and thin states appear also along the edges of the layer boundaries.
    This is due to \epsilon-limit behaviour at the edge of the $\PreR$-regions.

    \placefigure[top][fig:cases-integrator-layers]{
        Top row: illustration of the impact of \epsilon-limit behaviour (\in{section}[sec:abstraction-analysis-correctness]) when using $\ControlSpace$ unmodified to generate layers for the double integrator example (left).
        The creation of long, thin states along the edges of the layers during the inner refinement of each layer can be combatted by slightly shrinking $\ControlSpace$ as demonstrated by the partition on the right.
        Layers generated with the $\PreR$ operator and a 5\% shrunk $\ControlSpace$ for the double integrator system are highlighted in the bottom figure in different shades of green.
        8 layers are generated until convergence.
        The shown partition consists of 106 parts in $\StateSpace$.
    }{
        \bTABLE[offset=0mm,frame=off]
            \bTR[boffset=4mm]
                \bTD \externalfigure[cases-integrator-layers-prer100][width=0.494\textwidth] \eTD
                \bTD \externalfigure[cases-integrator-layers-prer95][width=0.494\textwidth] \eTD
            \eTR
            \bTR
                \bTD[nc=2] \externalfigure[cases-integrator-layers][width=\textwidth] \eTD
            \eTR
        \eTABLE
    }

    It is possible to combat this refinement behaviour by shrinking the control region during the layer generation.
    \in{Figure}[fig:cases-integrator-layers] shows the effects of \epsilon-limit behaviour on the partition in the top left frame.
    The panel on the right shows the same layered refinement but the control space was shrunk by 5\% during the generation of the layers, here from $\ClosedInterval{-1}{1}$ to $\ClosedInterval{-0.95}{0.95}$.
    This creates a \quotation{buffer zone} at the edges of the control space which allow the inner refinement steps to avoid the \epsilon-limit behaviour.
    Due to the smaller resulting $\PreR$-layers, an additional layer is required until the generator converges.
    As the bottom panel of \in{Figure}[fig:cases-integrator-layers] demonstrates, only a small border between the outermost layer and the no-region remains due to the shrunk $\ControlSpace$.

    \in{Table}[tab:cases-integrator-layered-shrunk] shows the complete refinement results of this layer decomposition.
    Due to the elimination of the \epsilon-limit behaviour, 37 fewer states have been created compared to the unmodified $\PreR$ decomposition.
    The number of states that arise just from the layer decomposition alone is 106 (\in{Figure}[fig:cases-integrator-layers] bottom), meaning that 23 additional polytopes were generated to enable the desired layer-to-layer transitions.
    The number of player 1 and 2 actions in the game graph has been reduced significantly and this is reflected in a much smaller run time of the game construction.
    After the analysis, 99\% of the state space is decided with 29 seconds elapsed since initialization.
    This is faster than two-step refinement with post-processing which profited from game simplification due to intermediate analysis results being available.
    It is also the smallest state space partition of all positive robust refinement configurations tried.

    \placetable[top][tab:cases-integrator-layered-shrunk]{
        Refinement of transition $q_0 \rightarrow q_1$ of the double integrator reachability system using a layer decomposition generated by the robust predecessor with a 5\%-shrunk $\ControlSpace$ and four-step positive robust refinement with robust target expansion and small state suppression.
        See \in{section}[sec:cases-integrator-layered] for discussion.
    }{
        \RefinementTable{
            \RefinementTableRow[iteration=5,polys=129,onestates=268,oneactions=2565,twostates=2415,twoactions=36246,
                                total={0:29},refinement={0:01},gamegraph={0:25},analysis={0:02},
                                yes=81.8,no=17.1,maybe=1.0,figure=cases-integrator-iteration5-slprms]
        }
    }

\stopsubsection


\startbuffer[buf:cases-integrator-results-statistics]
    \setupTABLE[frame=off,rightframe=on]
    \setupTABLE[c][first][rightframe=off]
    \setupTABLE[r][last][bottomframe=on]
    \bTABLE[align={middle,lohi}]
        \bTR[topframe=off]
            \bTH[width=0.06\textheight] \eTH
            \bTH[width=0.09\textheight] \eTH
            \bTH[width=0.17\textheight] single-step \times 2 \eTH
            \bTH[width=0.17\textheight] two-step \eTH
            \bTH[width=0.17\textheight] two-step \par small suppression \eTH
            \bTH[width=0.17\textheight] layers \par four-step \par small suppression \eTH
            \bTH[width=0.17\textheight] shrunk layers \par four-step \par small suppression \eTH
        \eTR
        \bTR[topframe=off]
            \bTH Iter. \eTH
            \bTH \eTH
            \bTD min / avg / max \eTD
            \bTD min / avg / max \eTD
            \bTD min / avg / max \eTD
            \bTD min / avg / max \eTD
            \bTD min / avg / max \eTD
        \eTR
        \bTR[topframe=on]
            \bTH[nr=3] 1-4 \par neg. \eTH
            \bTD polytopes \eTD
            \bTD[nc=5] 21 / 21 / 21 \eTD
        \eTR
        \bTR
            \bTD elapsed \eTD
            \bTD[nc=5] 0:01 / 0:01 / 0:01 \eTD
        \eTR
        \bTR
            \bTD \% decided \eTD
            \bTD[nc=5] 23.8 / 23.8 / 23.8 \eTD
        \eTR
        \bTR[topframe=on]
            \bTH[nr=3] 5 \eTH
            \bTD polytopes \eTD
            \bTD 48 / 50 / 53 \eTD
            \bTD 68 / 85 / 97 \eTD
            \bTD 49 / 54 / 60 \eTD
            \bTD 165 / 168 / 171 \eTD
            \bTD 128 / 130 / 133 \eTD
        \eTR
        \bTR
            \bTD elapsed \eTD
            \bTD 0:04 / 0:04 / 0:05 \eTD
            \bTD 0:11 / 0:21 / 0:36 \eTD
            \bTD 0:04 / 0:05 / 0:07 \eTD
            \bTD 1:19 / 1:24 / 1:27 \eTD
            \bTD 0:28 / 0:29 / 0:31 \eTD
        \eTR
        \bTR
            \bTD \% decided \eTD
            \bTD 30.7 / 31.0 / 31.4 \eTD
            \bTD 35.5 / 38.4 / 39.6 \eTD
            \bTD 35.5 / 36.7 / 39.2 \eTD
            \bTD 93.4 / 95.0 / 96.7 \eTD
            \bTD 99.0 / 99.0 / 99.0 \eTD
        \eTR
        \bTR[topframe=on]
            \bTH[nr=3] 6 \eTH
            \bTD polytopes \eTD
            \bTD 166 / 194 / 239 \eTD
            \bTD 227 / 277 / 317 \eTD
            \bTD 83 / 99 / 114 \eTD
            \bTD  \eTD
            \bTD  \eTD
        \eTR
        \bTR
            \bTD elapsed \eTD
            \bTD 1:55 / 4:00 / 11:56 \eTD
            \bTD 2:16 / 6:06 / 16:36 \eTD
            \bTD 0:18 / 0:25 / 0:36 \eTD
            \bTD - \eTD
            \bTD - \eTD
        \eTR
        \bTR
            \bTD \% decided \eTD
            \bTD 53.6 / 55.8 / 58.5 \eTD
            \bTD 70.7 / 74.8 / 79.4 \eTD
            \bTD 53.6 / 61.8 / 71.0 \eTD
            \bTD  \eTD
            \bTD  \eTD
        \eTR
        \bTR[topframe=on]
            \bTH[nr=3] 7 \eTH
            \bTD polytopes \eTD
            \bTD 239 / 280 / 321 \eTD
            \bTD 300 / 353 / 394 \eTD
            \bTD 124 / 132 / 137 \eTD
            \bTD  \eTD
            \bTD  \eTD
        \eTR
        \bTR
            \bTD elapsed \eTD
            \bTD 4:04 / 7:14 / 17:13 \eTD
            \bTD 3:10 / 7:24 / 17:59 \eTD
            \bTD 0:26 / 0:41 / 0:50 \eTD
            \bTD - \eTD
            \bTD - \eTD
        \eTR
        \bTR
            \bTD \% decided \eTD
            \bTD 69.3 / 72.0 / 73.3 \eTD
            \bTD 87.8 / 95.6 / 99.5 \eTD
            \bTD 76.2 / 83.8 / 89.8 \eTD
            \bTD  \eTD
            \bTD  \eTD
        \eTR
        \bTR[topframe=on]
            \bTH[nr=3,bottomframe=on] 8 \eTH
            \bTD polytopes \eTD
            \bTD 296 / 351 / 408 \eTD
            \bTD 333 / 389 / 435 \eTD
            \bTD 141 / 151 / 163 \eTD
            \bTD  \eTD
            \bTD  \eTD
        \eTR
        \bTR
            \bTD elapsed \eTD
            \bTD 6:15 / 12:35 / 27:24 \eTD
            \bTD 3:26 / 8:53 / 18:07 \eTD
            \bTD 0:31 / 0:47 / 0:58 \eTD
            \bTD - \eTD
            \bTD - \eTD
        \eTR
        \bTR
            \bTD \% decided \eTD
            \bTD 81.6 / 84.3 / 85.6 \eTD
            \bTD 95.5 / 99.2 / 99.8 \eTD
            \bTD 89.9 / 96.5 / 99.3 \eTD
            \bTD  \eTD
            \bTD  \eTD
        \eTR
    \eTABLE
\stopbuffer

\startsubsection[title={Comparison and Discussion},reference=sec:cases-integrator-results]

    % Rotation value has to be flipped for some reason (maybe because it refers
    % to the page that includes the figure, not the figure itself?
    % % TODO check rotation in final document
    \placetable[here,\doifoddpageelse{270}{90}][tab:cases-integrator-results-statistics]{
        Double integrator performance results for 5 configurations of the positive robust refinement procedure.
        Shown are the minimum, average and maximum number of polytopes in the $X$-partition, elapsed time after analysis and volume-percentage of the state space that has been identified as part of $\InitialStates$ or $\StateSpace \setminus \InitialStates$ from 8 runs of each procedure.
        Tables \in[tab:cases-integrator-negative] to \in[tab:cases-integrator-layered-shrunk] show the median runs with respect to total elapsed time in detail.
        Discussion in \in{section}[sec:cases-integrator-results].
    }{
        \startframedtext[width=\textheight,offset=0mm,frame=off,topframe=off,bottomframe=off]
            \getbuffer[buf:cases-integrator-results-statistics]
        \stopframedtext
    }

    Statistics from 8 runs of the 5 presented refinement configurations are given in \in{Table}[tab:cases-integrator-results-statistics].
    The negative refinement was shared by all procedures, then the different methods were applied for 4 iterations or 1 iteration if layer decomposition was applied.
    The runs shown above in detail are the median runs with respect to the elapsed time in the final iteration.

    The most striking observation from this table is the variability in partition size and elapsed time exhibited by the procedures not based on a layer decomposition.
    Randomization in the $\RefinePos$ kernel apparently has a significant effect on the refinement performance.
    Elapsed times for both refinement methods without post-processing vary by more than 15 minutes and the state space partition size by up to 100 polytopes.
    The variability of the non-layered procedure with small state suppression is much less, but still varies by half a minute.
    In contrast, the layered methods vary only by a few seconds and less than 10 polytopes in the state space partition.
    The results of the layer decomposition with shrunk control space show no variability at all in the volume of decided state space and less than 3 seconds of variability in the total elapsed time.
    One can conclude that the layer decomposition has a strong stabilizing effect on the refinement that counters the variability of the randomization of $\RefinePos$ and results in methods that deliver consistently good and dependable performance.

    Missing in the implementation is the leveraging of robust progress guarantees by the game graph abstraction after robust refinement.
    This would speed up the methods further as robust reachability could be established without the need for abstraction.
    Player actions for many polytopes would then not have to be computed and game construction, which is undeniably the bottleneck of the entire solution scheme, would be cheaper.

    An issue that arose during the performance benchmark was numerical instability when operating on very small polytopes.
    3 runs of the single-step procedure had to be repeated due to a faulty game construction detected by the implementation.
    In every case the fault was a problem in the calculation of the $\PreP$-regions for extremely small polytopes.
    This is either an instability in the geometry library (not unthinkable considering that it is a custom development) and/or a general problem with polytope sizes near the smallest representable scale.
    Additional measures that avoid very fine partitioning could be implemented to combat this.
    Currently there is a size threshold under which states are not refined further but this does not stop the creation of very small states completely.
    Instead one could refuse any partitioning that produces a tiny polytope at the cost of refinement progress.

\stopsubsection

\startsubsection[title={Neutral Refinement},reference=sec:cases-integrator-neutral]

    \placetable[top][tab:cases-integrator-neutral]{
        Refinement of the double integrator reachability system with 2 applications of safety refinement followed by 5 applications of self-loop removal.
        See \in{section}[sec:cases-integrator-neutral] for discussion.
    }{
        \RefinementTable{
            \RefinementTableRow[iteration=5,polys=201,onestates=412,oneactions=6660,twostates=6438,twoactions=142464,
                                total={4:04},refinement={0:36},gamegraph={3:14},analysis={0:13},
                                yes=80.8,no=17.1,maybe=2.1,figure=cases-integrator-iteration5-neutral]
        }
    }

    Safety refinement twice, then 5 times self-loop removal.
    Partition and analysis results shown in \in{Table}[tab:cases-integrator-neutral].
    Not competitive to layered refinement in size of partition or elapsed time but better than the robust methods without post-processing.
    Refinement took much longer than for any of the robust methods because game graph had to be partially constructed during the self-loop refinement.
    Notable that partition is very fine around $y = 0$ and quite coarse for larger values of $|y|$.
    Can be explained by dynamics, which has shear characteristics.
    Inherent \quotation{drift} of traces is much stronger away from $y = 0$, therefore self-loops are less likely to occur.
    The only way to remove self-loops near $y = 0$ is by partitioning the state space so fine, that all polytopes $\State{i}$ fulfill $\State{i} \ominus \RandomSpace$.

    Neutral refinement can provide solution despite not even knowing about the reachability target.
    This is a disadvantage as the partition size shows but also means that such refinement procedures are likely to genenerate paritions that work for diverse objectives.
    While the robust reachability refinement targets a specific transition, neutral refinement has the potential to work for multiple transitions if they exist.

\stopsubsection

