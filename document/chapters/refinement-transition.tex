A decomposition approach is presented that extracts a series of reachability problems from the product game.
These sub-problems are solved with positive robust refinement, which is computationally inexpensive even when multi-step dynamics is taken into account.
Solutions of the sub-problems are transferred back to the product game through refinement.
When all reachability problems have been solved, a solution for the original problem emerges.


\startsubsection[title={Transition-based Reachability Decomposition},reference=sec:refinement-transition-decomposition]

    Because of the stuttering equivalence of paths in $\Next$-free LTL, the product game $\ProductGame$ can be decomposed into a set of co-safe reachability/avoidance problems.
    The idea behind this decomposition is motivated by an example:

    Assume the recurrence objective $\Globally \Finally \varphi$ is specified for some LSS, translated to a one-pair Streett automaton as shown in Table \in[tab:theory-logic-objectives].
    One possible satisfying path through the automaton is $(q_0 q_1)^\omega$.
    Because recurrence is a $\Next$-free specification, any stuttering equivalent path $q_0^+ q_1^+ q_0^+ q_1^+ ...$ is also satisfying, so remaining in any of the two automaton states for a finite amount number of steps before transitioning has no consequence with respect to the acceptance condition.
    Based on this observation, two reachability problems are extracted from the product game:
    First, $\TransitionReach{q_0}{q_1}$ where player 1 has to reach some state $q_1$-associated player state of the product game almost-surely, starting from a state $\Tuple{\State{j}}{q_0}$ and only visiting $q_0$-associated states until a target state is reached.
    Second, $\TransitionReach{q_1}{q_0}$ which is defined analogously but with the roles of $q_0$ and $q_1$ exchanged.
    
    Let $\InitialStates^\TransitionReach{q_0}{q_1}$ and $\InitialStates^\TransitionReach{q_1}{q_0}$ be the sets of satisfying initial states of the LSS for problems $\TransitionReach{q_1}{q_0}$ and $\TransitionReach{q_1}{q_0}$, respectively.
    Then a player 1 strategy $\TransitionStrategy{q_0}{q_1}$ exists that leads any trace starting in $\InitialStates^\TransitionReach{q_0}{q_1}$ almost-surely and in finite time to the state space region where an associated play of the product game switches from a $q_0$- to a $q_1$-associated state, i.e.\ the region defined by $\varphi$.
    An analogous strategy $\TransitionStrategy{q_1}{q_0}$ exists for traces starting in $\InitialStates^\TransitionReach{q_1}{q_0}$ with a target region defined by $\neg \varphi$.
    Based on these strategies an almost-sure winning player 1 strategy for full product game can be assembled.
    Let $\VecState$ be a trace starting in some state $\Tuple{\State{i}}{q_0}$.
    Player 1 plays with $\TransitionStrategy{q_0}{q_1}$ until a state $\Tuple{X_j}{q_1}$ is reached.
    Player 1 then switches to the strategy $\TransitionStrategy{q_1}{q_0}$ until a state $\Tuple{X_k}{q_0}$ is reached.
    Then player 1 switches back to strategy $\TransitionStrategy{q_0}{q_1}$ and keeps switching whenever the automaton state changes in the play.
    Because automaton runs induced by a composite strategy alternating in this fashion are stuttering equivalent to $(q_0 q_1)^\omega$, the recurrence objective is satisfied almost-surely.
    Note that each sub-problem strategy is guaranteed to achieve its reachability goal in finite time as the sub-problems are interpreted in the co-safe setting.

    The example illustrates how a solution to a verification problem involving a $\Next$-free LTL specification can emerge from solutions to a series of reachability sub-problems extracted from the product game based on transitions of the objective automaton.
    Generally, it is not sufficient to just consider a single path and its stuttering equivalents.
    The above strategy construction fails when a trace enters the region $\StateSpace \setminus \InitialStates^\TransitionReach{q_0}{q_1}$ while the corresponding play transitions from a $q_0$-associated to a $q_1$-associated state.
    However, since the decomposition targets individual automaton transitions and not entire paths, strategies for all possible paths through the automaton can be constructed once a solution for every reachability sub-problem is available.

    For a product game $\ProductGame$, generated with the objective automaton $\Automaton$, a reachability/avoidance sub-problem $\TransitionReach{q}{q'}$ for an automaton transition from $q$ to $q'$ can be constructed as follows:
    The elements of the current state space partition are sorted into 3 categories.
    First,

    \startformula
        \ReachStates{q}{q'} = \Set{ \State{i} \mid \Tuple{\State{i}}{q} \in P_1 \MidAnd \State{i} \notin \NoStates{q} \MidAnd ( \QNext{i}{q} = q' \MidOr \YesStates{q} ) } \EndComma
    \stopformula

    the state space partition elements whose union has to be reached.
    These are state space parts where a transition to the target automaton state happens with any of the next player 1 actions of the product game.
    Also included are all parition elements that were already recognized as satisfying for the origin $q$ in a previous analysis of $\ProductGame$.
    Second,

    \startformula
        \RefineStates{q}{q'} = \Set{ \State{i} \mid \Tuple{\State{i}}{q} \in P_1 \MidAnd \State{i} \notin \NoStates{q} \MidAnd \QNext{i}{q} = q } \EndComma
    \stopformula

    the state space partition elements that do not trigger an automaton transition with their player 1 actions.
    These elements will be the subject of refinement.
    Due to stuttering equivalence, any finite number of transitions inside this region can be made without affecting satisfaction of the objective.
    And finally,

    \startformula
        \AvoidStates{q}{q'} = \IndexedStates{i}{I} \setminus \left( \ReachStates{q}{q'} \cup \RefineStates{q}{q'} \right) \EndComma
    \stopformula

    the elements where a transition to any other automaton state happens with the next player 1 action, as well as all elements from the no-set of the last product game analysis.
    These states are to be avoided.
    The three sets are disjunct except for the special case $q = q'$, where $\ReachStates{q}{q'} \cap \RefineStates{q}{q'} \ne \emptyset$.

    To summarize, the goal of sub-problem $\TransitionReach{q}{q'}$ is to refine the state space partition elements in $\RefineStates{q}{q'}$ such that $\ReachStates{q}{q'}$ can be reached almost-surely and in finite time while avoiding the region $\AvoidStates{q}{q'}$.
    Note that the individual reachability/avoidance sub-problems can overlap, i.e. a state space partition element can be the subject of refinement of more than one sub-problem.
    The decomposition of the product game graph is therefore not disjunct.

\stopsubsection


\placefigure[top][fig:refinement-transition-jagged]{
    Illustration of how jaggedness in a positive refinement target region causes very fine partitioning and how post-processing of $\RefinePos$ can reduce the number of generated state space partition elements.
    See section \in[sec:refinement-transition-reachability] for a detailed discussion.
}{
    \bTABLE
        \setupTABLE[frame=off]
        \bTR
            \bTD[nc=2] (a) no post-processing \eTD
        \eTR
        \bTR
            \bTD \externalfigure[refinement-transition-jagged-ref-attrr][width=0.47\textwidth] \eTD
            \bTD \externalfigure[refinement-transition-jagged-ref-ana][width=0.47\textwidth] \eTD
        \eTR
        \bTR
            \bTD[nc=2] (b) convex hull \eTD
        \eTR
        \bTR
            \bTD \externalfigure[refinement-transition-jagged-hull-attrr][width=0.47\textwidth] \eTD
            \bTD \externalfigure[refinement-transition-jagged-hull-ana][width=0.47\textwidth] \eTD
        \eTR
        \bTR
            \bTD[nc=2] (c) small state suppression, one iteration \eTD
        \eTR
        \bTR
            \bTD \externalfigure[refinement-transition-jagged-sup1-attrr][width=0.47\textwidth] \eTD
            \bTD \externalfigure[refinement-transition-jagged-sup1-ana][width=0.47\textwidth] \eTD
        \eTR
        \bTR
            \bTD[nc=2] (d) small state suppression, two iterations \eTD
        \eTR
        \bTR
            \bTD \externalfigure[refinement-transition-jagged-sup2-attrr][width=0.47\textwidth] \eTD
            \bTD \externalfigure[refinement-transition-jagged-sup2-ana][width=0.47\textwidth] \eTD
        \eTR
    \eTABLE
}

\startsubsection[title={Robust Reachability Refinement},reference=sec:refinement-transition-reachability]

    In section \in[sec:refinement-holistic-positive] a positive refinement procedure was presented based on the $\RefinePos$ kernel.
    Limitation was that yes-states have to exist for method to be applicable.
    While this is not generally a given, any co-safe objective has yes-states guaranteed.
    In particular, this includes the reachability/avoidance systems from the transition decomposition.

    Idea is to construct a multi-step refinement procedure based on robust dynamics.
    Positive robust refinement has progress guarantee.
    One-step robust reachability can generally be decided with the $\ActR$ operator without need for game construction (see section \in[sec:refinement-robust]).
    Restriction to robust reachability allows skipping of expensive game construction for analysis.
    While this means that the probabilistic dynamics is ignored completely, abstraction step is removed and entire procedure has polynomial complexity.
    Best of both worlds: multi-step refinement in the robust framework, but consideration of probabilistic dynamics by analysing every couple of refinements.

    Procedure: evolution of \cite[Svorenova2017] positive refinement to multi-step procedure based on reachability decomposition.
    First pick a transition and extract reachability problem.
    Refine every state wrt target region using $\RefinePos$ refinement.
    Use $ActR$ condition to determine states for which robust reachability is fulfilled.
    Extend target region with new yes states.
    Refine again wrt to the extended target region and iterate for a given number of times.
    Transfer partition to full system and analyse.

    Additional tweaks possible to improve method.
    Known that small states cannot be targeted individually due to probabilistic dynamics have no self loops and are therefore unlikely to be a problem if surrounded by bigger states for which robust satisfaction can be established.
    Expansion of target region can be accelerated by considering all small polytopes as satisfying (without proper probabilistic check).
    This brings some of the probabilistic tolerance back into the robust dynamics at the cost of losing the progress guarantee for a few special cases (practice shows that ignoring small states is not an issue as long as they are safe).

    Post-processing of $\RefinePos$ can improve refinement performance significantly.
    Idea is to over- or underapproximate the robust region from $\RefinePos$ in order to decrease size of state space partition.
    Overapproximation has the potential to accelerate progress but no guarantees exist.
    Underapproximation inherits guarantee at the cost of progress per step.
    Figure \in[fig:refinement-transition-jagged] illustrates the problem of over-refinement and how post-processing affects the complexity of the state space partition.
    Situation after one step of robust refinement for the double integrator test system introduced later in section \in[sec:cases-integrator].
    Green states are recognized yes-states and the reachability target.
    Implementation of $\RefinePos$ using $\AttrR$, according to Algorithms \in[alg:refinement-robust-kernel] and \in[alg:refinement-robust-control].
    Orange states are $\AttrR$-region determined in refinement.
    Issue here is jaggedness of target region, which is reflected and amplified in the $\AttrR$-region.

    Easy to see that refinement without post-processing (a) can quickly lead to a snowball effect as jaggedness increases with every iteration and moves to smaller scales.
    Overapproximation shown in (b), method is to take $\AttrR$-region of every state that is refined and refine with respect to its convex hull.
    Cut away region is always a polytope, increase in complexity of state space partition mainly by convex partitioning of remaining region.
    Issue: progress guarantee lost in general (in the figure, the analysis on the right shows that in this case it works out).
    Underapproximation in (c) by dropping polytopes $Y$ where $Y \ominus W = \emptyset$ from the $\AttrR$-region.
    This reduces small-scale jaggedness while keeping the progress guarantee intact.
    Possiblility to compensate for less progress by going to multi-step robust refinement.
    2-iteration robust refinement shown in (d), first iteration is orange, second yellow.
    Similar state count as no post-processing after one iteration but much volume recognized as yes-states in the analysis.
    More progress than convex hull approximation with only a few states more but full progress guarantee.

\stopsubsection


\startsubsection[title={Layered Robust Reachability Refinement},reference=sec:refinement-transition-layered]

    \cite[Svorenova2017] introduced the idea of a layer decomposition that works only for reachability but splits problem into multiple decoupled subproblems.
    Use one-step reachability property of predecessor to generate layers and then solve single-step reachability for each layer wrt its inner companion.
    Problem: $\AttrR$-based refinement is robust but they used the non-robust $\Pre$.
    However, for robust refinement, importance of the PreR also recognized by \cite[Svorenova2017].
    Propsal: combine transition decomposition, layer decomposition and robust refinement.
    Use PreR which is more aligned with robust refinement and provides guarantee that single-step robust solution can be found.
    Hybrid approach between multi-step and single-step: general idea of using the layers to move towards the target is multi-step, but transitions from layer to layer individually are single step.

    Advantages: decoupling into more, simpler subproblems.
    Limits jaggedness since $\PreR$ of a convex target region is convex (for convex control region).
    Prescribes basic structure of progress towards target, limits the effects of the randomization introduced in $\GetCtrl$
    Parallelization possible.
    But solution for outer layers depends on solution of inner layers otherwise multi-step concept falls apart.

    Procedure:
    First extract reachability problem for transition.
    Then decompose reachability problems into PreR layers. % TODO formulas!
    Solve reachability problem for each layer-to-layer transition.
    Combine into solution for reachability problem.
    Apply partition to product game.

    To combat problem of \epsilon-limit behaviour, shrink layer-generating control space.
    Other optimizations from robust refinement still apply (target expansion, ignoring of small but safe states, post-processing).

\stopsubsection


\startsubsection[title={Transition Selection},reference=refinement-transition-selection]

    If a solution for every transition of the objective automaton has been found through refinement, the LSS can be fully analysed with respect to the objective specification due to the strategy construction outlined in section \in[sec:refinement-transition-decomposition].
    However, the individual reachability sub-problems are not completely independent as they initially share the state space partition of the original LSS.
    While it is possible to solve the sub-problems independently and then combine the resulting state space partitions into a single paritition, this combination is likely to generate many additional states.
    Solving the reachability systems sequentially, using only one state space partition that is handed from refinement procedure to refinement procedure, can be beneficial as the refinement applied to achieve one transition may provide a partial solution to a following sub-problem.

    Satisfying paths through the objective automaton can be plentiful even when considering stuttering equivalence.
    While it is generally not sufficient for the determination of $\InitialStates$ to pick one satisfying path and only refine with respect to the transitions that occur along this specific path, this approach to selecting transition for refinement can lead to faster availability of partial analysis results than a breadth-first exploration of the automaton starting from its initial state.
    The issues arising with the selection of optimal paths as the basis for transition refinement occur also in the synthesis of optimal controllers.

\stopsubsection

