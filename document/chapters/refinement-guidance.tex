When given a partition of the state space, that is too coarse and therefore does not permit a membership decision with respect to $\InitialStates$ for every state, how can one determine which parts to refine and how should that refinement look like?

Framework of counterexample-based abstraction refinement (CEGAR) \cite[authoryears][TODO].
Goal is to derive examples of behaviour in the abstraction that is not possible in the actual system, then apply refinement so this behaviour is eliminated in the updated abstraction.
This is not an exact fit for the kind of analysis carried out here.
The analysis procedure described above does not return specific counterexample plays where player 2 wins with non-zero probability but only the sets $P_{\Yes}$, $P_{\No}$ and $P_{\Maybe}$.
Only states from $P_\Maybe$, associated with state space partition elements

\startformula
    \Set{ \State{i} \mid \exists q \in Q : \State{i} \in \MaybeStates{q} } \EndComma
\stopformula

require refinement as the analysis is guaranteed to return a partial result of the full solution.
For the refinement itself, knowledge of the game graph and the LSS dynamics have to be used in addition to the analysis results.

\cite[Svorenova2017] separated their refinement procedures into two categories named positive and negative.
Positive refinement has the goal of enlarging the total volume of polytopes in $P_\Yes$ while negative refinement aims to enlarge the volume of polytopes in $P_\No$.
For simple objectives such as reachability, the analysis will provide feedback to a refinement more immediately than for complex objectives, where multiple refinement steps might have to be taken until the first states of $\ProductGame$ can be decided by the analysis.
Refinement should therefore not exclusively rely on the sets $P_{\Yes}$, $P_{\No}$ and $P_{\Maybe}$ or else the abstraction-analysis-refinement procedure could get stuck if progress halts at any point in time.

Here, an additional class called neutral refinement is introduced, motivated by the following observations:
A single \quotation{bad} transition that cannot be avoided with probability 1 enables player 2 to win the game.
At the same time, if a single \quotation{good} transition can be ensured by player 1 with non-zero probability in a \quotation{neutral} environment then player 1 can still almost-surely satisfy the objective. 
LTL only determines the order of events and, aside from the $\Next$-operator, not the temporal distance between them.
So in almost-sure verification of an LTL objective without $\Next$ there is no need to satisfy the objective in an efficient manner (due to stuttering equivalence of traces). % TODO formalize stuttering here or in preliminaries?
Player 1 can take any finite amount of time to arrive at a good transition as long the environment is neutral, i.e.\ as long as states in which player 2 can force a bad transition can be avoided almost-surely.
Hence, avoiding bad transitions (from player 1's perspective) in the game graph is arguably just as important as enabling good transitions.
Procedures in the category of neutral refinement make it possible to avoid bad transitions for longer by breaking patterns in the game graph that allow player 2 to win, therefore creating a neutral environment for player 1.
An almost-sure winning player 1 strategy for the objective may not immediately exist after a neutral refinement step but finding one through positive refinement should have become easier.

The design of fully automated refinement is non-trivial.
With multiple refinement procedures at one's disposal, questions arise about the order in which procedures should be applied, how often they should be applied and how often the system should be analysed between refinement steps.
General answers to these questions are hard to find, as the best strategy for refinement coordination will depend on the objective, the properties of the LSS and even on the meaning of \quotation{best}.
One can optimize for the shortest time until a certain percentage of the state space is decided in the analysis, the smallest number of states generated in the partition, the suitability of the generated game graph for controller synthesis purposes and many other metrics.
If optimizing for performance, note has to be taken that application of a refinement procedure invalidates (parts of) the game graph.
When chaining refinement procedures without an intermediate analysis, procedures relying on insights from the game graph incur significant additional computational cost as the game's actions have to be recomputed, which involves operations of exponential complexity in the number of states.
Procedures based only on the system dynamics have the advantage of being chainable without extra computational cost.

